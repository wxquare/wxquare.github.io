2019年3月1日
tersewang
上周工作：
1.准备追踪测试数据集和批处理脚本
2.将visp python版本和线上结构对齐
3.跑测试集，根据测试结果和andy哥一起分析追踪效果不理想的原因，目前iou重合率在0.95左右

本周工作：
1.跑测试集，在效果和性能上对python版本的visp进行优化


2019年3月8日
tersewang：
本周工作：
1、研究GPU解码Video_Codec_SDK，能实现GPU视频解码（40%）
2、基于KCF追踪的弹幕，完成opencv和opencv-contrib的动态和静态链接（50%）
3、协助yuanli多进程版本的多目标追踪（10%）
下周工作：
1.基于KCF的弹幕落地
2.opencv的学习和追踪算法的优化



2019年3月15日
tersewang
本周工作：
1、从Opencv中抽离kcf源码，实现单独静态编译；通过分析源码和elf文件，发现有些全局变量可避免，例如单个ColorName变量1.2M（30%）
2、调研DaSiamRPM，搭建服务端运行环境、demo程序运行（30%）
3、学习Pytorch和机器学习相关知识。（40%）

1.andorid IOS 追踪调研  visual library 周一
2.tensorflow lite demo  周一
3.pytorch 转 tflite，以及模型的可视化 周二
https://blog.csdn.net/computerme/article/details/84144930
https://heartbeat.fritz.ai/deploying-pytorch-and-keras-models-to-android-with-tensorflow-mobile-a16a1fb83f2
4.DaSiamRPN源码阅读
 DaSiamRPN测试程序分析: https://blog.csdn.net/yiran103/article/details/84031907
 SiamRPN阅读笔记：https://blog.csdn.net/fzp95/article/details/80982201
 SiamRPN论文：http://openaccess.thecvf.com/content_cvpr_2018/papers/Li_High_Performance_Visual_CVPR_2018_paper.pdf



2019年3月25日：
tersewang
本周工作：
1、阅读DaSiamRPN论文和相关代码，理解其基本原理。
2、尝试了两种pytorch模型到tflite的方法，一种通过keras中转然后转换tflite；另外一种是通过onnx转tensorflow再中转。
3、验证转出来的tflite模型的正确性，发现转出来的模型跑出来的结果和pytorch不同，还需进一步分析。

下周工作：
1、通过tensorflow验证转出来的dasiamrpn模型是否正确
2、通过一个简单的网络验证pytorch到tflite的可行性


1. golang笔记2篇，channel，并发、内存和垃圾回收（完成50%）
2. 《指数基金投资指南》50%、亿万5集、voa2篇


2019年4月1日：
tersewang
本周工作：
1. 分析DaSiamRPN模型和模型转换失败的原因，放弃keras模型转换，选择使用onnx转tensorflow模型；由于DaSiamRPN模型的特殊性，需要将原模型分解成3部分分别导出tensorflow模型。（40%）
2. 使用python版本tflite，验证了DaSiamRPN模型从pytorch、onnx、tf到tflite是可行的。（30%）
3. 学习tflite android代码，调研DaSiamRPN在android端开发和部署。（30%）


下周工作：
1. 开发DaSiamRPN在andorid上的demo。 
2. 线上bug修复
3. bofeng bug修复

个人学习：
1. golang学习博客内存分配、垃圾回收、并发调度、延迟、析构和缓存池
2. 《指数基金投资指南》完，亿万第二季，voa2篇



2019年4月8日：
tersewang:
本周工作：
1、研究tensorflow lite 官方android demo代码，开发DaSiamRPN在android的demo。除了深度学习模型之外，还包含大量的矩阵操作，在android上实现非常困难。目前已经验证DaSiamRPN在android从输入到输出大概需要3到4s的时间，正在尝试使用Nd4j库来解决android上的矩阵运算问题。（70%）
2、解决视频广告软植入的bug（30%）

下周工作：
1、继续开发DaSiamRPN在android上的demo。

个人学习：
1、oj 10
2、golang面经 1
3、oa 2
4、如何成为一个有趣的人 30%
5、pyhton爬虫学习

追踪算法待办项：
1.visp 静止判断
2.visp 矩形标注
3.4867 和 5317 追踪的帧和实际的帧不一样，语义分割有问题，协调尽快上线新版语义分割算法，排查问题是否还会出现。
4.进度条不准确
5.2407 kcf静止有问题，xiaorong提供测试脚本问题，已经解决
6.输出已经跟踪成功的坐标。不能因为某一帧挂了就全部不输出了
7.排查测试环境 #2819追踪失败原因



在2019上半年内，实现移动端算法部署和优化的能力，推动算法在移动端的使用
1. golang笔记2篇，channel，并发、内存和垃圾回收
2. 通过tensorflow验证dasiamrpn模型
3. 使用mnist模型验证pytorch到tensorflow的可行性
4. 《指数基金投资指南》50%、亿万5集、voa2篇



4. tflite 怎么跑DaSiamRPN ？？
tflite object tracking demo on mobile device
https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android
pytorch tensorflow 学习

下周计划：
1、研究DaSiamRPN在终端的落地（80%）
2、项目涉及相关算法内容学习（20%）
3、pytorch学习和DaSiamRPN源码学习
4、golang学习总结，反射、并发和测试
5、《影响力》看完
6、两篇voa英文听力

=============================
需要准备的内容：
1、opencv-python
2、pytorch和tensorFlow
3、DaSiamRPN 论文学习

早上在66.8搭建了一个DaSiamRPN运行环境：
1、需要pytoch和gpu的支持，代码全是python2.7
2、运行了一个demo程序/data/home/tersewang/DaSiamRPN/code，python demo.py fps在90左右
3、基于机器学习追踪，模型文件87M

1、ubunu环境安装配置，因为需要显卡的支持，在66.8机器实验
  pip install torch==0.3.1


 (featureExtract): Sequential(
    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): ReLU(inplace)
    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): ReLU(inplace)
    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace)
    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace)
    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv_r1): Conv2d(256, 5120, kernel_size=(3, 3), stride=(1, 1))
  (conv_r2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv_cls1): Conv2d(256, 2560, kernel_size=(3, 3), stride=(1, 1))
  (conv_cls2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
  (regress_adjust): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))


SiamRPNvot(
  (featureExtract): Sequential(
    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(2, 2))
    (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): ReLU(inplace)
    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1))
    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): ReLU(inplace)
    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1))
    (9): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU(inplace)
    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1))
    (12): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (13): ReLU(inplace)
    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv_r1): Conv2d(256, 5120, kernel_size=(3, 3), stride=(1, 1))
  (conv_r2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
  (conv_cls1): Conv2d(256, 2560, kernel_size=(3, 3), stride=(1, 1))
  (conv_cls2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))
  (regress_adjust): Conv2d(20, 20, kernel_size=(1, 1), stride=(1, 1))

toco \
--input_file=detect_model.pb \
--input_format=TENSORFLOW_GRAPHDEF \
--output_format=TFLITE \
--inference_type=FLOAT \
--input_type=FLOAT \
--output_file=detect_model.tflite

toco \
--input_file=/tmp/mnist_graph_def_with_ckpts/opt_mnist_graph.pb \
--input_format=TENSORFLOW_GRAPHDEF \
--output_format=TFLITE \
--inference_type=FLOAT \
--input_type=FLOAT \
--input_arrays=input_tensor \
--output_arrays=softmax_tensor \
--input_shapes=1,28,28,1 \
--output_file=/tmp/mnist_graph_def_with_ckpts/mnist.tflite


tflite_convert \
  --output_file=detect_model.tflite \
  --graph_def_file=detect_model.pb \
  --input_arrays=input \
  --output_arrays=MobilenetV1/Predictions/Reshape_1


   pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-locale-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/concrt140.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-utility-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-math-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-locale-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/linux-x86_64/libgomp.so.1'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-stdio-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-convert-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/macosx-x86_64/libusb-1.0.0.dylib'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-time-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/linux-x86/libgomp.so.1'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-math-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-environment-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-multibyte-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-runtime-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/msvcp140.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-stdio-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-string-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/vcruntime140.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-multibyte-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-filesystem-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-time-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/msvcp140.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-environment-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/concrt140.dll'
        pickFirst 'org/bytedeco/javacpp/api-ms-win-crt-heap-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-heap-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-heap-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/vcruntime140.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-convert-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-string-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-runtime-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86/api-ms-win-crt-filesystem-l1-1-0.dll'
        pickFirst 'org/bytedeco/javacpp/windows-x86_64/api-ms-win-crt-utility-l1-1-0.dll'
--------------------- 
作者：nearbyYoung 
来源：CSDN 
原文：https://blog.csdn.net/u012846789/article/details/81808166 
版权声明：本文为博主原创文章，转载请附上博文链接！